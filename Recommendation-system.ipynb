{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "072ce091",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f15c4f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id item_id  rating\n",
      "0       0     938       4\n",
      "1       0     630       8\n",
      "2       0     682       5\n",
      "3       1     464       8\n",
      "4       1     542       2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "NUM_USERS = 10_000\n",
    "NUM_ITEMS = 1_000\n",
    "user_id = np.arange(start = 0, stop = NUM_USERS)\n",
    "item_id = np.arange(start = 0, stop = NUM_ITEMS)\n",
    "np.random.seed(42)\n",
    "user_item_dict = defaultdict(list)\n",
    "genres = ['Action','Comedy','Drama','Fantasy','Horror','Mystery','Romance','Thriller']\n",
    "\n",
    "for id in user_id:\n",
    "    #each user rates 3 to 5 items\n",
    "    num_random_item = np.random.randint(low = 3, high = 5)\n",
    "    \n",
    "    rand_rating = np.random.randint(low=1, high=10, size=num_random_item)\n",
    "    rand_items = np.random.choice(item_id, size = num_random_item, replace = False)\n",
    "    \n",
    "    for u_id, i_id, rating in zip([id] * num_random_item, rand_items, rand_rating):\n",
    "        user_item_dict['user_id'].append(u_id)\n",
    "        user_item_dict['item_id'].append(i_id)\n",
    "        user_item_dict['rating'].append(rating)\n",
    "\n",
    "ratings = pd.DataFrame(user_item_dict)\n",
    "ratings[['user_id', 'item_id']] = ratings[['user_id', 'item_id']].astype(str)\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b1373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  item_id           genres\n",
      "0       0  Horror ,Romance\n",
      "1       1          Fantasy\n",
      "2       2            Drama\n",
      "3       3   Drama ,Fantasy\n",
      "4       4  Fantasy ,Horror\n"
     ]
    }
   ],
   "source": [
    "item_genre_dict = defaultdict(list)\n",
    "for id in item_id:\n",
    "    #random no. of genres\n",
    "    num_rand_genre = np.random.randint(low=1, high=3)\n",
    "    rand_genres = np.random.choice(genres, size = num_rand_genre, replace = False)\n",
    "    item_genre_dict['item_id'].append(id)\n",
    "    item_genre_dict['genres'].append(' ,'.join(list(rand_genres)))\n",
    "    \n",
    "items = pd.DataFrame(item_genre_dict)\n",
    "items = items.astype(str)\n",
    "print(items.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ae88a",
   "metadata": {},
   "source": [
    "# Popular Based "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aff1bf",
   "metadata": {},
   "source": [
    "- Intuitive\n",
    "- Most basic\n",
    "- Usually used when user has no data yet\n",
    "- All users get the same recommendation set. Not personalized.\n",
    "- IMdB uses weighted rating formula for this\n",
    "\n",
    "- FORMULA: WR = (v/(v+m))*R + (m/(v+m)) * C\n",
    "\n",
    "- WR: Weighted Rating\n",
    "- v: number of votes for the item\n",
    "- m: minimum number of votes to be listed in the popular items (defined by > 80th percentile of all votes)\n",
    "- R: average rating for an item\n",
    "- C: average rating across the whole dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af82206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the weighted training\n",
    "def weighted_rating(v, m, R, C):\n",
    "    return ((v/(v+m)) * R) + ((m/(v+m)) * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b57e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def assign_popular_based_score(rating_df, item_df, user_col, item_col, rating_col):\n",
    "    vote_count = (rating_df.groupby(item_col, as_index=False).agg({user_col:'count', rating_col: 'mean'}))\n",
    "    vote_count.columns = [item_col, 'vote_count', 'avg_rating']\n",
    "    \n",
    "    C = np.mean(vote_count['avg_rating'])\n",
    "    m = np.percentile(vote_count['vote_count'], 80)\n",
    "    vote_count = vote_count[vote_count['vote_count'] > m]\n",
    "    R = vote_count['avg_rating']\n",
    "    v = vote_count['vote_count']\n",
    "    vote_count['weighted_rating'] = weighted_rating(v, m, R, C)\n",
    "    \n",
    "    vote_count = vote_count.merge(item_df, on=[item_col], how='left')\n",
    "    popular_items = vote_count.loc[:,[item_col, 'genres', 'vote_count', 'avg_rating', 'weighted_rating']]\n",
    "    return popular_items\n",
    "\n",
    "popular_items = assign_popular_based_score(ratings, items, 'user_id', 'item_id', 'rating')\n",
    "popular_items = popular_items.sort_values('weighted_rating', ascending = False)\n",
    "\n",
    "#plot based on popularity\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "sns.barplot(data = popular_items.head(10), y = 'item_id', x = 'weighted_rating')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811cc544",
   "metadata": {},
   "source": [
    "# Content Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89919bd3",
   "metadata": {},
   "source": [
    "- Based on genres feature to find similar item\n",
    "- one hot encoding of the genre column\n",
    "- find the similarity b/w each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00468320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 similar movie to item_id 86: \n",
      "    item_id          genres\n",
      "46       46  Fantasy ,Drama\n",
      "86       86  Drama ,Fantasy\n",
      "129     129  Fantasy ,Drama\n",
      "405     405  Fantasy ,Drama\n",
      "519     519  Fantasy ,Drama\n",
      "657     657  Fantasy ,Drama\n",
      "673     673  Fantasy ,Drama\n",
      "789     789  Fantasy ,Drama\n",
      "810     810  Drama ,Fantasy\n",
      "812     812  Fantasy ,Drama\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def top_k_items(item_id, top_k, corr_mat, map_name):\n",
    "    #get all cosine_similarities for this item id with others, sort it, get last top k, reverse it\n",
    "    top_items = corr_mat[item_id, :].argsort()[-top_k:][::-1]\n",
    "    top_items = [map_name[e] for e in top_items]\n",
    "    return top_items\n",
    "\n",
    "#getting all items that are rated\n",
    "rated_items = items.loc[items['item_id'].isin(ratings['item_id'])].copy()\n",
    "\n",
    "#genre = list of genres column split by \",\": it becomes a series where each row is a list\n",
    "genre = rated_items['genres'].str.split(\",\", expand = True)\n",
    "\n",
    "# generate distinct genres\n",
    "all_genre = set()\n",
    "for c in genre.columns:\n",
    "    distinct_genre = genre[c].str.lower().str.strip().copy()\n",
    "    all_genre.update(distinct_genre)\n",
    "all_genre.remove(None)\n",
    "\n",
    "# generate matrix w item_id and genre\n",
    "item_genre_mat = rated_items[['item_id', 'genres']].copy()\n",
    "item_genre_mat['genres'] = item_genre_mat['genres'].str.lower().str.strip()\n",
    "\n",
    "# one hot encoding of genres. result is a matrix where index is item_id and rows are what genres they belong to\n",
    "for genre in all_genre:\n",
    "    item_genre_mat[genre] = np.where(item_genre_mat['genres'].str.contains(genre), 1, 0)\n",
    "item_genre_mat = item_genre_mat.drop(['genres'], axis = 1)\n",
    "item_genre_mat = item_genre_mat.set_index('item_id')\n",
    "\n",
    "#compute similarity matrix\n",
    "corr_mat = cosine_similarity(item_genre_mat)\n",
    "\n",
    "# dict with index to name\n",
    "index_to_name = {ind:name for ind, name in enumerate(item_genre_mat.index)}\n",
    "name_to_index = {v:k for k,v in index_to_name.items()}\n",
    "\n",
    "#getting 10 similar movies to movie no. 86\n",
    "similar_movies = top_k_items(name_to_index['86'], top_k = 10, corr_mat = corr_mat, map_name = index_to_name)\n",
    "\n",
    "print(\"top 10 similar movie to item_id 86: \")\n",
    "print(items.loc[items['item_id'].isin(similar_movies)])\n",
    "\n",
    "#the movie 86 itself is also listed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb10548",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f72bc",
   "metadata": {},
   "source": [
    "### 2 Main approaches\n",
    "1. Memory Based\n",
    "2. Model Based\n",
    "\n",
    "- User Based Implementation:\n",
    "    1. Find group of similar users based on similarity metric of your choice\n",
    "    2. Average the rating of each item based on the group of similar users\n",
    "    3. Rank the item based on the descending average rating, and recommend the target user with the item they have not interacted with before\n",
    "    - Recommendation is personalized for each user\n",
    "    - Limitation: cold-start problem: we need prior information about the user to derive the simlarity for this user and others. Fix: provide the new user with popular-based recommendations first.\n",
    "    \n",
    "- Item Based Implementation\n",
    "    1. Find group of similar items based on similrity metric of your choice\n",
    "    2. Select up to the top k most similar items to recommend\n",
    "    - similar to popular based/content based filtering\n",
    "    - difference is that the user-item matrix is used to rather than rating on genres like above methods implemented\n",
    "    - Limitation: same as user based implementation\n",
    "\n",
    "## Memory Based\n",
    "\n",
    "- calculates similarity directly matrix from user-item matrix\n",
    "- Similarity Metrics:\n",
    "    1. Pearson Correlation\n",
    "    2. Cosine similarity\n",
    "    3. Others\n",
    "\n",
    "\n",
    "\n",
    "- Limitation: it is memory-based i.e. the interaction between user and item is memorized and retrieve results based on that. Can pose a problem w scalability. In reality, the imabalanc between no. of users and items makes the user-item matrix very sparse - leading to poor generalization of the predicted result.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c404f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35002\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "row = ratings['user_id']\n",
    "col = ratings['item_id']\n",
    "data = ratings['rating']\n",
    "\n",
    "mat = csr_matrix((data, (row, col)), shape = (NUM_USERS, NUM_ITEMS))\n",
    "mat.eliminate_zeros()\n",
    "\n",
    "# calculate sprasity matrix\n",
    "print(len(mat.nonzero()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c732f165",
   "metadata": {},
   "source": [
    "### Better approach\n",
    "\n",
    "- Instead of computation with the user-item interaction matrix, decompose this matrix into user and item latent factor matrix using matrix factorization. \n",
    "- The idea is that observed user-item matrix is constructed from underlying user and item latent factor matrices\n",
    "- Goal is to minimize loss between the reconstructed matrix and the original matrix\n",
    "- Then the inner product of the user and item latent factor matrix can be used for inferencing an unobserved rating\n",
    "- ML comes into play during matrix factorization\n",
    "\n",
    "\n",
    "### Model Based approach\n",
    "\n",
    "- solves scalability issue\n",
    "- 3 techniques used here:\n",
    "    1. Truncated SVD:\n",
    "        - sklearn library\n",
    "        - variant of singular value decomposition that calculates only the k-largest singular values\n",
    "        - applies linear dimensionality reduction \n",
    "        - works well w sparse matrix\n",
    "        - users matrix: N X k matrices\n",
    "        - items matrix: M X k matr|ices\n",
    "        - Disadv: The scalability is still a problem for this algorithm, even if we reduce the size of a matrix with the decomposition method. \n",
    "        - Disadv: the explainability would be a problem too. We don't know how to describe each latent factor in terms of human interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5448a399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    item_id            genres\n",
      "18       18            Horror\n",
      "72       72             Drama\n",
      "86       86    Drama ,Fantasy\n",
      "171     171    Action ,Horror\n",
      "188     188   Mystery ,Action\n",
      "664     664           Mystery\n",
      "743     743            Comedy\n",
      "835     835   Fantasy ,Comedy\n",
      "916     916  Fantasy ,Mystery\n",
      "976     976    Drama ,Romance\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# initial hyperparameter\n",
    "epsilon = 1e-9\n",
    "n_latent_factors = 10\n",
    "\n",
    "# generate item lantent features\n",
    "item_svd = TruncatedSVD(n_components = n_latent_factors)\n",
    "item_features = item_svd.fit_transform(mat.transpose()) + epsilon\n",
    "\n",
    "# generate user latent features\n",
    "user_svd = TruncatedSVD(n_components = n_latent_factors)\n",
    "user_features = user_svd.fit_transform(mat) + epsilon\n",
    "\n",
    "item_corr_mat = cosine_similarity(item_features)\n",
    "\n",
    "# get top k item\n",
    "similar_items = top_k_items(name_to_index['86'],\n",
    "                            top_k = 10,\n",
    "                            corr_mat = item_corr_mat,\n",
    "                            map_name = index_to_name)\n",
    "print(items.loc[items['item_id'].isin(similar_items)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7babe03",
   "metadata": {},
   "source": [
    "    2. Funk Matrix Factorization:\n",
    "        - objective of FunkFM is to estimate the latent factor matrix and the bias termed minimizing the loss between the original explicit rating and the reconstructed prediction rating. Therefore, this kind of approach is model-based.\n",
    "        - this model only takes into account the explicit rating and it doesn't care about the implicit rating\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "775ee472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.6446\n",
      "    item_id           genres\n",
      "60       60          Fantasy\n",
      "86       86   Drama ,Fantasy\n",
      "180     180   Romance ,Drama\n",
      "542     542          Fantasy\n",
      "570     570  Romance ,Horror\n",
      "589     589   Horror ,Action\n",
      "788     788    Drama ,Comedy\n",
      "814     814           Comedy\n",
      "818     818  Fantasy ,Comedy\n",
      "985     985          Romance\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, accuracy\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection.split import train_test_split\n",
    "\n",
    "def pred2dict(predictions, top_k=None):\n",
    "    \n",
    "    rec_dict = defaultdict(list)\n",
    "    for user_id, item_id, actual_rating, pred_rating, _ in predictions:\n",
    "        rec_dict[user_id].append((item_id, pred_rating))        \n",
    "        \n",
    "    return rec_dict\n",
    "\n",
    "def get_top_k_recommendation(rec_dict, user_id, top_k, ind2name):\n",
    "    \n",
    "    pred_ratings = rec_dict[user_id]\n",
    "    # sort descendingly by pred_rating\n",
    "    pred_ratings = sorted(pred_ratings, key=lambda x: x[1], reverse=True)\n",
    "    pred_ratings = pred_ratings[:top_k]\n",
    "    recs = [ind2name[e[0]] for e in pred_ratings]\n",
    "    \n",
    "    return recs\n",
    "\n",
    "# prepare train and test sets\n",
    "reader = Reader(rating_scale=(1,10))\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "train, test = train_test_split(data, test_size=.2, random_state=42)\n",
    "\n",
    "# init and fit the funk mf model\n",
    "algo = SVD(random_state = 42)\n",
    "algo.fit(train)\n",
    "pred = algo.test(test);\n",
    "\n",
    "# evaluation the test set\n",
    "accuracy.rmse(pred)\n",
    "\n",
    "# extract the item features from algo\n",
    "item_corr_mat = cosine_similarity(algo.qi)\n",
    "\n",
    "\n",
    "similar_items = top_k_items(name_to_index['86'],\n",
    "                            top_k = 10,\n",
    "                            corr_mat = item_corr_mat,\n",
    "                            map_name = index_to_name)\n",
    "\n",
    "print(items.loc[items['item_id'].isin(similar_items)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c1258",
   "metadata": {},
   "source": [
    "        3. Generalized Matrix Factorization (GMF) (Keras)\n",
    "            - Idea: the embedding layers that dense the sparse input user and item vector (user-item interaction matrix) can be seen as a latent factor matrix in the normal matrix factorization process.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f1b11c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation on the test set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 2.749397039413452,\n",
       " 'loss': 4.362840175628662,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 4.362840175628662}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    item_id             genres\n",
      "25       25   Thriller ,Action\n",
      "47       47            Mystery\n",
      "86       86     Drama ,Fantasy\n",
      "297     297  Fantasy ,Thriller\n",
      "376     376             Action\n",
      "409     409             Action\n",
      "460     460           Thriller\n",
      "713     713    Thriller ,Drama\n",
      "915     915    Fantasy ,Action\n",
      "928     928             Comedy\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def df_to_ds(df):\n",
    "    return {\n",
    "        \"user_id\" : tf.constant(df['user_id'].tolist()),\n",
    "        \"item_id\" : tf.constant(df['item_id'].tolist()),\n",
    "        'rating' : tf.constant(df['rating'].tolist())\n",
    "    }\n",
    "\n",
    "class RankingModel(keras.Model):\n",
    "\n",
    "    def __init__(self, user_id, item_id, embedding_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # user model\n",
    "        input = keras.Input(shape=(), dtype=tf.string)\n",
    "        x = keras.layers.StringLookup(\n",
    "            vocabulary = user_id, mask_token = None\n",
    "            )(input)\n",
    "        output = keras.layers.Embedding(\n",
    "            input_dim = len(user_id) + 1,\n",
    "            output_dim = embedding_size,\n",
    "            name = 'embedding'\n",
    "        )(x)\n",
    "        self.user_model = keras.Model(inputs = input,\n",
    "                                      outputs = output,\n",
    "                                      name = 'user_model')\n",
    "\n",
    "        # item model\n",
    "        input = keras.Input(shape=(), dtype=tf.string)\n",
    "        x = keras.layers.StringLookup(\n",
    "            vocabulary = item_id, mask_token = None\n",
    "            )(input)\n",
    "        output = keras.layers.Embedding(\n",
    "            input_dim = len(item_id) + 1,\n",
    "            output_dim = embedding_size,\n",
    "            name = 'embedding'\n",
    "        )(x)\n",
    "        self.item_model = keras.Model(inputs = input,\n",
    "                                  outputs = output,\n",
    "                                  name = 'item_model')\n",
    "\n",
    "        # rating model\n",
    "        concat_shape = self.user_model.layers[-1].output_shape[1] \\\n",
    "        + self.item_model.layers[-1].output_shape[1] \n",
    "\n",
    "        input = keras.Input(shape=(concat_shape,))\n",
    "        x = keras.layers.Dense(256, activation = 'relu')(input)\n",
    "        x = keras.layers.Dense(64, activation = 'relu')(x)\n",
    "        output = keras.layers.Dense(1)(x)\n",
    "        \n",
    "        self.ratings = keras.Model(\n",
    "            inputs = input,\n",
    "            outputs = output,\n",
    "            name = 'rating_model'\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, item_id = inputs\n",
    "\n",
    "        user_emb = self.user_model(user_id)\n",
    "        item_emb = self.item_model(item_id)\n",
    "        concat = tf.concat([user_emb, item_emb], axis = 1)\n",
    "        prediction = self.ratings(concat)\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "class GMFModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, user_id, item_id, embedding_size):\n",
    "        super().__init__()\n",
    "        self.ranking_model = RankingModel(user_id,\n",
    "                                          item_id,\n",
    "                                          embedding_size)\n",
    "        self.task = tfrs.tasks.Ranking(\n",
    "            loss = keras.losses.MeanSquaredError(),\n",
    "            metrics = [keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "    \n",
    "    def call(self, features):\n",
    "        return self.ranking_model(\n",
    "            (features[0]['user_id'], features[0]['item_id'])\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        label = features[0]['rating']\n",
    "        return self.task(labels = label,\n",
    "                         predictions = self(features))\n",
    "\n",
    "\n",
    "# preprocess\n",
    "train, test = train_test_split(ratings, train_size = .8, random_state=42)\n",
    "train, test = df_to_ds(train), df_to_ds(test)\n",
    "\n",
    "# init model\n",
    "embedding_size = 32\n",
    "model = GMFModel(user_id.astype(str), item_id.astype(str), embedding_size)\n",
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adagrad(learning_rate = .01)\n",
    ")\n",
    "\n",
    "# fitting the model\n",
    "model.fit(train, epochs=3, verbose=0)\n",
    "\n",
    "# evaluate with the test data\n",
    "result = model.evaluate(test, return_dict=True, verbose=0)\n",
    "print(\"\\nEvaluation on the test set:\")\n",
    "display(result)\n",
    "\n",
    "# extract item embedding\n",
    "item_emb = model.ranking_model.item_model.layers[-1].get_weights()[0]\n",
    "\n",
    "\n",
    "item_corr_mat = cosine_similarity(item_emb)\n",
    "\n",
    "similar_items = top_k_items(name_to_index['86'],\n",
    "                            top_k = 10,\n",
    "                            corr_mat = item_corr_mat,\n",
    "                            map_name = index_to_name)\n",
    "\n",
    "print(items.loc[items['item_id'].isin(similar_items)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b8b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
